<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="style.css" type="text/css" />
</head>
<body>
<h1 id="sarath-chandra-jiguru">Sarath Chandra Jiguru</h1>
<hr />
<blockquote>
<p>Specialties: Java, Python, Hadoop, Linux, Data Engineering<br /> M.Tech in CSE MIT, Manipal</p>
</blockquote>
<hr />
<h2 id="experience-2-years-1-months-1-year-internship">Experience (2 years 1 month(s) + 1 year internship)</h2>
<dl>
<dt>Since 2014 Jan</dt>
<dd><p><em>Data Engineer at <a href="https://adnear.com/">AdNear</a></em> (Bangalore, India).</p>
<p><strong>User Profiling</strong>(Hive, Hadoop, Java): Worked on a simple rule based location oriented user segmentation project. Involved in reducing time complexity of the profiling algorithm, by reducing the search space. Responsible for querying different Places API to build Point of interest(s) database, identifying new place categories and updating profiled users to a lookup table.</p>
<p>Worked on a prototype to cluster users by using their location (where the person is), App used (what the person is doing), time (Using the person's local time).</p>
<p><strong>Log Ingestion</strong>(Java, Python): One of the developers for a full fledged Log ingestion system built at AdNear. The project is responsible for absorbing unremitting log messages from message queues, and storing them to a central store.</p>
<p><strong>Analytics API</strong>(Web Services): Responsible to maintain different count stores and to develop API endpoints to retrieve various aggregated counts, which were presented to customers as insights.</p>
<p>Having 1 Year 9 months experience.</p>
</dd>
<dt>2013 Aug-Nov</dt>
<dd><p><em>Associate Data Engineer at <a href="http://www.deltax.com/">DeltaX</a></em> (Bangalore, India).</p>
<p><strong>Re-targeting Platform</strong>: Worked on a simple retargetting platform built with DynamoDB and Node.js. The former is used to store the user cookie id and at max 6 latest products s/he has visited on a client e-commerce site. There after whenever the person visits any website, the targeted products are shown as ads.</p>
<p><strong>Real time data visualization</strong>: Worked on a prototype using node.js, syslog-ng, Kafka, Storm, MongoDB. syslog-ng is used to emit server events as messages, stored on Kafka queue, and are ultimately processed by storm, and are saved to a MongoDB collection.</p>
<p>Had 4 months experience.</p>
</dd>
<dt>2012 Jun-2013 Jun</dt>
<dd><p><em>Internship at <a href="http://www.verisigninc.com/">Verisign Inc</a></em> (Bangalore, India). Verisign Inc is registry of .com and .net domains.</p>
<p><strong>Internet Profiling Service</strong>(Java, Hadoop, Mahout): This Biggie at Verisigninc is used to crawl all of the .com and .net domains(once in every month) to collect various kinds of information. Worked in bits and parts of Address extraction from a possible contact-us page. Responsible for making improvements to website classification algorithms.</p>
<p><strong>Clustering web pages</strong>: It is my thesis project. It is basically a project on information filtering umberella. Used to identify the exactly the same kind of web pages(mirror pages) with only change in website name or Hostname. It was built as Hadoop project, to understand the concept of Mapreduce. The project crawls the home pages of websites given, extract HTML templates, creating murmur hashes, using the hashes at reducer to collect similar websites.</p>
<p><strong>Analysis of social sharing habits</strong>: The project listens to the external social networking APIs like Twitter and Bitly to identify phrases, that are trending, and analyse how the domain name registrations are influenced.</p>
<p>Had 1 year experience.</p>
</dd>
</dl>
<h2 id="languages-and-frameworks">Languages and Frameworks</h2>
<dl>
<dt>Java</dt>
<dd><p>confident. Written production ready code.</p>
</dd>
<dt>Python</dt>
<dd><p>confident. Written production ready code.</p>
</dd>
<dt>Javascript</dt>
<dd><p>Comfortable. Written bug free code.</p>
</dd>
<dt>PHP</dt>
<dd><p>can google and write code.</p>
</dd>
<dt>Hadoop</dt>
<dd><p>Having good knowledge on HDFS and Mapreduce.</p>
</dd>
<dt>Hive</dt>
<dd><p>Confident. Can write Hive sql queries.</p>
</dd>
<dt>Kafka</dt>
<dd><p>Confident. Worked on receiving data from consumers.</p>
</dd>
<dt>Storm</dt>
<dd><p>Confident. Had written code application logic using bolts and spouts concept.</p>
</dd>
<dt>Dropwizard</dt>
<dd><p>Confident. Written production ready code.</p>
</dd>
</dl>
<h2 id="education">Education</h2>
<dl>
<dt>2011-2013</dt>
<dd><p><em>Masters in CSE</em>, from Manipal Institute of Technology, Manipal University (Manipal, Karnataka, India).</p>
<p>Subject of interest: Data Mining and Business Analytics, Distributed Computing Systems, Web Services, Information and Storage Management.</p>
<p>CGPA: 7.39</p>
</dd>
<dt>2007-2011</dt>
<dd><p><em>Bachelors in CSE</em>, from Arora's Engineering College (Affilated to JNTUH Hyderabad, India).</p>
<p>Percentage: 70.9</p>
</dd>
<dt>2005-2007</dt>
<dd><p><em>12th grade(BIE, AP)</em>, from Vignan's Junior College (Guntur, AP, India).</p>
<p>Mathematics Physics and Chemistry as core subjects.</p>
<p>Percentage: 95.8</p>
</dd>
<dt>2004-2005</dt>
<dd><p><em>10th grade(BSE, AP)</em>, from St. Joseph's High School (Nagarjuna Sagar, TG, India).</p>
<p>Percentage: 86.7</p>
</dd>
</dl>
<h2 id="activities-and-interests">Activities and interests</h2>
<dl>
<dt>Hobbies</dt>
<dd><p>I like reading. I read books, blogs. Knowing about new startups, Apps. Watching TED talks.</p>
</dd>
<dt>Sports</dt>
<dd><p>I love swimming and volleyball.</p>
</dd>
</dl>
<h2 id="profies">Profies</h2>
<dl>
<dt>LinkedIn</dt>
<dd><p><a href="https://in.linkedin.com/in/sarathjiguru">Sarath Chandra Jiguru</a></p>
</dd>
<dt>Stackoverflow</dt>
<dd><p><a href="http://stackoverflow.com/users/2005230/tvastr">sarathjiguru</a></p>
</dd>
<dt>GitHub</dt>
<dd><a href="https://github.com/sarathjiguru">sarathjiguru</a>
</dd>
</dl>
<hr />
<blockquote>
<p><script type="text/javascript">
<!--
h='&#x67;&#x6d;&#x61;&#x69;&#108;&#46;&#x63;&#x6f;&#x6d;';a='&#64;';n='&#x73;&#x61;&#114;&#x61;&#116;&#104;&#46;&#106;&#x39;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+e+'<\/'+'a'+'>');
// -->
</script><noscript>&#x73;&#x61;&#114;&#x61;&#116;&#104;&#46;&#106;&#x39;&#32;&#x61;&#116;&#32;&#x67;&#x6d;&#x61;&#x69;&#108;&#32;&#100;&#x6f;&#116;&#32;&#x63;&#x6f;&#x6d;</noscript> • +91 903 511 6947 • 24 years old (21 July 1990)<br /> #13/1, 1st main, 1st cross, Srinivagillu, Vivek nagar post, Bangalore 560047, India</p>
</blockquote>
</body>
</html>
